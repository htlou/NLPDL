[2024-11-16 19:15:10,128] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11/16/2024 19:15:10 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -c /tmp/tmpxv49lnvq/test.c -o /tmp/tmpxv49lnvq/test.o
11/16/2024 19:15:10 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/data/align-anything/miniconda3/envs/jy-s/lib -Wl,-rpath-link,/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs /tmp/tmpxv49lnvq/test.o -laio -o /tmp/tmpxv49lnvq/a.out
11/16/2024 19:15:11 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -c /tmp/tmp42bav9hj/test.c -o /tmp/tmp42bav9hj/test.o
11/16/2024 19:15:11 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/data/align-anything/miniconda3/envs/jy-s/lib -Wl,-rpath-link,/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs /tmp/tmp42bav9hj/test.o -L/data/align-anything/miniconda3/envs/hantao_cham -L/data/align-anything/miniconda3/envs/hantao_cham/lib64 -lcufile -o /tmp/tmp42bav9hj/a.out
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                                  | 0/70 [00:00<?, ?it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 20%|██████████████████████████████▌                                                                                                                          | 14/70 [00:20<00:21,  2.61it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 1.0029, 'grad_norm': 0.28440651297569275, 'learning_rate': 0.00045454545454545455, 'epoch': 0.71}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                              
{'eval_loss': 0.9384337067604065, 'eval_accuracy': 0.65, 'eval_micro_f1': 0.65, 'eval_macro_f1': 0.2626262626262626, 'eval_runtime': 8.2224, 'eval_samples_per_second': 136.213, 'eval_steps_per_second': 0.608, 'epoch': 1.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 40%|█████████████████████████████████████████████████████████████▏                                                                                           | 28/70 [00:40<00:23,  1.77it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 0.9686, 'grad_norm': 0.6436449289321899, 'learning_rate': 0.0003787878787878788, 'epoch': 1.43}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                              
{'eval_loss': 0.9132208824157715, 'eval_accuracy': 0.65, 'eval_micro_f1': 0.65, 'eval_macro_f1': 0.2626262626262626, 'eval_runtime': 10.3561, 'eval_samples_per_second': 108.149, 'eval_steps_per_second': 0.483, 'epoch': 2.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 60%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 42/70 [01:00<00:13,  2.11it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 0.9671, 'grad_norm': 0.28473061323165894, 'learning_rate': 0.00030303030303030303, 'epoch': 2.14}
{'loss': 0.9511, 'grad_norm': 0.3380753993988037, 'learning_rate': 0.00022727272727272727, 'epoch': 2.86}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                              
{'eval_loss': 0.9072232842445374, 'eval_accuracy': 0.65, 'eval_micro_f1': 0.65, 'eval_macro_f1': 0.2626262626262626, 'eval_runtime': 10.2561, 'eval_samples_per_second': 109.203, 'eval_steps_per_second': 0.488, 'epoch': 3.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 56/70 [01:16<00:06,  2.21it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 0.9671, 'grad_norm': 0.36382266879081726, 'learning_rate': 0.00015151515151515152, 'epoch': 3.57}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                              
{'eval_loss': 0.9024648070335388, 'eval_accuracy': 0.65, 'eval_micro_f1': 0.65, 'eval_macro_f1': 0.2626262626262626, 'eval_runtime': 9.1443, 'eval_samples_per_second': 122.481, 'eval_steps_per_second': 0.547, 'epoch': 4.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [01:25<00:00,  2.47it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 0.9444, 'grad_norm': 0.72487473487854, 'learning_rate': 7.575757575757576e-05, 'epoch': 4.29}
{'loss': 0.9419, 'grad_norm': 1.4389090538024902, 'learning_rate': 0.0, 'epoch': 5.0}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [01:39<00:00,  1.43s/it]
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'eval_loss': 0.8999862670898438, 'eval_accuracy': 0.65, 'eval_micro_f1': 0.65, 'eval_macro_f1': 0.2626262626262626, 'eval_runtime': 9.6003, 'eval_samples_per_second': 116.663, 'eval_steps_per_second': 0.521, 'epoch': 5.0}
{'train_runtime': 100.3252, 'train_samples_per_second': 172.04, 'train_steps_per_second': 0.698, 'train_loss': 0.9632943562098912, 'epoch': 5.0}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.68s/it]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =       0.65
  eval_loss               =     0.9384
  eval_macro_f1           =     0.2626
  eval_micro_f1           =       0.65
  eval_runtime            = 0:00:08.96
  eval_samples_per_second =     124.92
  eval_steps_per_second   =      0.558
