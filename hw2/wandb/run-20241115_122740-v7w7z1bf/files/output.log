[2024-11-15 12:27:42,849] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11/15/2024 12:27:43 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -c /tmp/tmpx99rm5f2/test.c -o /tmp/tmpx99rm5f2/test.o
11/15/2024 12:27:43 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/data/align-anything/miniconda3/envs/jy-s/lib -Wl,-rpath-link,/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs /tmp/tmpx99rm5f2/test.o -laio -o /tmp/tmpx99rm5f2/a.out
11/15/2024 12:27:44 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -fPIC -O2 -isystem /data/align-anything/miniconda3/envs/hantao_cham/include -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/align-anything/miniconda3/envs/jy-s/include -I/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/include -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs -c /tmp/tmprodno4ia/test.c -o /tmp/tmprodno4ia/test.o
11/15/2024 12:27:44 - INFO - root - /data/align-anything/miniconda3/envs/jy-s/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/data/align-anything/miniconda3/envs/jy-s/lib -Wl,-rpath-link,/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib -L/data/align-anything/miniconda3/envs/jy-s/targets/x86_64-linux/lib/stubs /tmp/tmprodno4ia/test.o -L/data/align-anything/miniconda3/envs/hantao_cham -L/data/align-anything/miniconda3/envs/hantao_cham/lib64 -lcufile -o /tmp/tmprodno4ia/a.out
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                                                                                                                                                                     | 0/135 [00:00<?, ?it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 20%|████████████████████████████████████████████████████████▊                                                                                                                                                                                                                                   | 27/135 [00:24<00:35,  3.01it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 1.6717, 'grad_norm': 3.350285530090332, 'learning_rate': 1.953125e-05, 'epoch': 0.37}
{'loss': 1.3721, 'grad_norm': 3.989149570465088, 'learning_rate': 1.7968750000000003e-05, 'epoch': 0.74}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                                                                                                                                                                  
{'eval_loss': 1.3133840560913086, 'eval_accuracy': 0.5107913669064749, 'eval_micro_f1': 0.5107913669064749, 'eval_macro_f1': 0.1126984126984127, 'eval_runtime': 8.4393, 'eval_samples_per_second': 16.47, 'eval_steps_per_second': 0.355, 'epoch': 1.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 40%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                          | 54/135 [00:46<00:33,  2.42it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 1.3067, 'grad_norm': 3.2757530212402344, 'learning_rate': 1.6406250000000002e-05, 'epoch': 1.11}
{'loss': 1.1981, 'grad_norm': 5.004443168640137, 'learning_rate': 1.4843750000000002e-05, 'epoch': 1.48}
{'loss': 1.1548, 'grad_norm': 8.388704299926758, 'learning_rate': 1.3281250000000001e-05, 'epoch': 1.85}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                                                                                                                                                                  
{'eval_loss': 1.0700587034225464, 'eval_accuracy': 0.6258992805755396, 'eval_micro_f1': 0.6258992805755396, 'eval_macro_f1': 0.24893162393162394, 'eval_runtime': 5.2349, 'eval_samples_per_second': 26.553, 'eval_steps_per_second': 0.573, 'epoch': 2.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 81/135 [01:08<00:26,  2.04it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 0.9641, 'grad_norm': 11.938384056091309, 'learning_rate': 1.171875e-05, 'epoch': 2.22}
{'loss': 1.0195, 'grad_norm': 10.950777053833008, 'learning_rate': 1.0156250000000001e-05, 'epoch': 2.59}
{'loss': 1.0075, 'grad_norm': 8.13326358795166, 'learning_rate': 8.59375e-06, 'epoch': 2.96}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                                                                                                                                                                  
{'eval_loss': 0.9691257476806641, 'eval_accuracy': 0.6762589928057554, 'eval_micro_f1': 0.6762589928057554, 'eval_macro_f1': 0.3040607344632768, 'eval_runtime': 5.9514, 'eval_samples_per_second': 23.356, 'eval_steps_per_second': 0.504, 'epoch': 3.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                        | 108/135 [01:32<00:12,  2.13it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 0.9039, 'grad_norm': 6.51301908493042, 'learning_rate': 7.031250000000001e-06, 'epoch': 3.33}
{'loss': 0.8643, 'grad_norm': 6.428675174713135, 'learning_rate': 5.468750000000001e-06, 'epoch': 3.7}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):                                                                                                                                                                                                                                  
{'eval_loss': 0.9143706560134888, 'eval_accuracy': 0.6690647482014388, 'eval_micro_f1': 0.6690647482014388, 'eval_macro_f1': 0.309305476775698, 'eval_runtime': 5.962, 'eval_samples_per_second': 23.314, 'eval_steps_per_second': 0.503, 'epoch': 4.0}
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 135/135 [01:49<00:00,  2.18it/s]/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
{'loss': 0.8419, 'grad_norm': 5.495070457458496, 'learning_rate': 3.90625e-06, 'epoch': 4.07}
{'loss': 0.8096, 'grad_norm': 12.089545249938965, 'learning_rate': 2.3437500000000002e-06, 'epoch': 4.44}
{'loss': 0.8524, 'grad_norm': 8.16199779510498, 'learning_rate': 7.8125e-07, 'epoch': 4.81}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 135/135 [02:04<00:00,  1.08it/s]
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.                                                                                  
{'eval_loss': 0.905784010887146, 'eval_accuracy': 0.6906474820143885, 'eval_micro_f1': 0.6906474820143885, 'eval_macro_f1': 0.3339285714285714, 'eval_runtime': 5.5112, 'eval_samples_per_second': 25.221, 'eval_steps_per_second': 0.544, 'epoch': 5.0}
{'train_runtime': 125.2818, 'train_samples_per_second': 67.368, 'train_steps_per_second': 1.078, 'train_loss': 1.0617000738779703, 'epoch': 5.0}
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
/data/align-anything/miniconda3/envs/hantao_cham/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.51s/it]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.6906
  eval_loss               =     0.9058
  eval_macro_f1           =     0.3339
  eval_micro_f1           =     0.6906
  eval_runtime            = 0:00:10.78
  eval_samples_per_second =     12.886
  eval_steps_per_second   =      0.278
